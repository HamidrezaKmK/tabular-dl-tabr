{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0
        ]
    },
    "single_model_function": "bin.lightgbm_.main",
    "data": ":data/TabZilla-OpenML-adult-tid=7592-fold=0",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8997906357061287,
                "recall": 0.9543114759613767,
                "f1-score": 0.9262494489526018,
                "support": 29723.0
            },
            "1": {
                "precision": 0.820084790673026,
                "recall": 0.6621028987057439,
                "f1-score": 0.7326744392495709,
                "support": 9349.0
            },
            "accuracy": 0.8843929156429157,
            "macro avg": {
                "precision": 0.8599377131895773,
                "recall": 0.8082071873335603,
                "f1-score": 0.8294619441010863,
                "support": 39072.0
            },
            "weighted avg": {
                "precision": 0.8807189233490833,
                "recall": 0.8843929156429157,
                "f1-score": 0.8799315546622242,
                "support": 39072.0
            },
            "cross-entropy": 0.2664368210163442,
            "roc-auc": 0.9418098730681284,
            "f1-weighted": 0.8799315546622242,
            "f1-macro": 0.8294619441010863,
            "f1-micro": 0.8843929156429157,
            "score": 0.8843929156429157
        },
        "val": {
            "0": {
                "precision": 0.8954996186117468,
                "recall": 0.9477933261571583,
                "f1-score": 0.920904693423977,
                "support": 3716.0
            },
            "1": {
                "precision": 0.7962184873949579,
                "recall": 0.6484174508126604,
                "f1-score": 0.7147571900047147,
                "support": 1169.0
            },
            "accuracy": 0.8761514841351075,
            "macro avg": {
                "precision": 0.8458590530033523,
                "recall": 0.7981053884849094,
                "f1-score": 0.8178309417143459,
                "support": 4885.0
            },
            "weighted avg": {
                "precision": 0.8717412475999912,
                "recall": 0.8761514841351075,
                "f1-score": 0.871572772953738,
                "support": 4885.0
            },
            "cross-entropy": 0.2905036341161767,
            "roc-auc": 0.9237420131289015,
            "f1-weighted": 0.871572772953738,
            "f1-macro": 0.8178309417143459,
            "f1-micro": 0.8761514841351075,
            "score": 0.8761514841351075
        },
        "test": {
            "0": {
                "precision": 0.8890005022601708,
                "recall": 0.9526372443487621,
                "f1-score": 0.9197194076383476,
                "support": 3716.0
            },
            "1": {
                "precision": 0.805094130675526,
                "recall": 0.6218990590248076,
                "f1-score": 0.7017374517374517,
                "support": 1169.0
            },
            "accuracy": 0.8734902763561925,
            "macro avg": {
                "precision": 0.8470473164678485,
                "recall": 0.7872681516867848,
                "f1-score": 0.8107284296878996,
                "support": 4885.0
            },
            "weighted avg": {
                "precision": 0.8689213726015322,
                "recall": 0.8734902763561925,
                "f1-score": 0.8675554554483481,
                "support": 4885.0
            },
            "cross-entropy": 0.28717169390229225,
            "roc-auc": 0.9275967517525305,
            "f1-weighted": 0.8675554554483481,
            "f1-macro": 0.8107284296878996,
            "f1-micro": 0.8734902763561925,
            "score": 0.8734902763561925
        }
    }
}
