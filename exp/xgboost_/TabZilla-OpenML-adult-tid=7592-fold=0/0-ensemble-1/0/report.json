{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0
        ]
    },
    "single_model_function": "bin.xgboost_.main",
    "data": ":data/TabZilla-OpenML-adult-tid=7592-fold=0",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9031639501438159,
                "recall": 0.9507788581233388,
                "f1-score": 0.9263599560749348,
                "support": 29723.0
            },
            "1": {
                "precision": 0.8120020560267284,
                "recall": 0.6759011659000963,
                "f1-score": 0.7377269277917226,
                "support": 9349.0
            },
            "accuracy": 0.8850071662571662,
            "macro avg": {
                "precision": 0.8575830030852721,
                "recall": 0.8133400120117176,
                "f1-score": 0.8320434419333287,
                "support": 39072.0
            },
            "weighted avg": {
                "precision": 0.8813510778029926,
                "recall": 0.8850071662571662,
                "f1-score": 0.8812245603588275,
                "support": 39072.0
            },
            "cross-entropy": 0.2493045892201769,
            "roc-auc": 0.9454486805033879,
            "f1-weighted": 0.8812245603588275,
            "f1-macro": 0.8320434419333287,
            "f1-micro": 0.8850071662571662,
            "score": 0.8850071662571662
        },
        "val": {
            "0": {
                "precision": 0.8980061349693251,
                "recall": 0.9453713670613563,
                "f1-score": 0.9210802307288936,
                "support": 3716.0
            },
            "1": {
                "precision": 0.7913669064748201,
                "recall": 0.6586826347305389,
                "f1-score": 0.7189542483660131,
                "support": 1169.0
            },
            "accuracy": 0.8767656090071648,
            "macro avg": {
                "precision": 0.8446865207220726,
                "recall": 0.8020270008959476,
                "f1-score": 0.8200172395474533,
                "support": 4885.0
            },
            "weighted avg": {
                "precision": 0.8724869419068735,
                "recall": 0.8767656090071648,
                "f1-score": 0.8727106763006014,
                "support": 4885.0
            },
            "cross-entropy": 0.2820335194505375,
            "roc-auc": 0.9234660004917123,
            "f1-weighted": 0.8727106763006014,
            "f1-macro": 0.8200172395474533,
            "f1-micro": 0.8767656090071648,
            "score": 0.8767656090071648
        },
        "test": {
            "0": {
                "precision": 0.8940936863543788,
                "recall": 0.9451022604951561,
                "f1-score": 0.9188906331763474,
                "support": 3716.0
            },
            "1": {
                "precision": 0.786833855799373,
                "recall": 0.6441402908468776,
                "f1-score": 0.7083725305738476,
                "support": 1169.0
            },
            "accuracy": 0.8730808597748209,
            "macro avg": {
                "precision": 0.8404637710768759,
                "recall": 0.7946212756710169,
                "f1-score": 0.8136315818750975,
                "support": 4885.0
            },
            "weighted avg": {
                "precision": 0.8684259807415227,
                "recall": 0.8730808597748209,
                "f1-score": 0.8685128108749508,
                "support": 4885.0
            },
            "cross-entropy": 0.27668078768651677,
            "roc-auc": 0.9295366670933083,
            "f1-weighted": 0.8685128108749508,
            "f1-macro": 0.8136315818750975,
            "f1-micro": 0.8730808597748209,
            "score": 0.8730808597748209
        }
    }
}
