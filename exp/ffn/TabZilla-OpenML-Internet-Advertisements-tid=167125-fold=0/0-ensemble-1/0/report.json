{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0
        ]
    },
    "single_model_function": "bin.ffn.main",
    "data": ":data/TabZilla-OpenML-Internet-Advertisements-tid=167125-fold=0",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9785522788203753,
                "recall": 0.9945504087193461,
                "f1-score": 0.9864864864864865,
                "support": 367.0
            },
            "1": {
                "precision": 0.9991111111111111,
                "recall": 0.9964539007092199,
                "f1-score": 0.9977807367953839,
                "support": 2256.0
            },
            "accuracy": 0.9961875714830347,
            "macro avg": {
                "precision": 0.9888316949657432,
                "recall": 0.995502154714283,
                "f1-score": 0.9921336116409352,
                "support": 2623.0
            },
            "weighted avg": {
                "precision": 0.9962345989301351,
                "recall": 0.9961875714830347,
                "f1-score": 0.9962004890396213,
                "support": 2623.0
            },
            "cross-entropy": 0.019899909523205472,
            "roc-auc": 0.9991648066554583,
            "f1-weighted": 0.9962004890396213,
            "f1-macro": 0.9921336116409352,
            "f1-micro": 0.9961875714830347,
            "score": 0.9961875714830347
        },
        "val": {
            "0": {
                "precision": 0.9777777777777777,
                "recall": 0.9565217391304348,
                "f1-score": 0.967032967032967,
                "support": 46.0
            },
            "1": {
                "precision": 0.9929328621908127,
                "recall": 0.9964539007092199,
                "f1-score": 0.9946902654867257,
                "support": 282.0
            },
            "accuracy": 0.9908536585365854,
            "macro avg": {
                "precision": 0.9853553199842953,
                "recall": 0.9764878199198274,
                "f1-score": 0.9808616162598464,
                "support": 328.0
            },
            "weighted avg": {
                "precision": 0.9908074540109357,
                "recall": 0.9908536585365854,
                "f1-score": 0.9908114980206498,
                "support": 328.0
            },
            "cross-entropy": 0.04792163491997214,
            "roc-auc": 0.9947579401788467,
            "f1-weighted": 0.9908114980206498,
            "f1-macro": 0.9808616162598464,
            "f1-micro": 0.9908536585365854,
            "score": 0.9908536585365854
        },
        "test": {
            "0": {
                "precision": 0.95,
                "recall": 0.8260869565217391,
                "f1-score": 0.8837209302325582,
                "support": 46.0
            },
            "1": {
                "precision": 0.9722222222222222,
                "recall": 0.9929078014184397,
                "f1-score": 0.9824561403508771,
                "support": 282.0
            },
            "accuracy": 0.9695121951219512,
            "macro avg": {
                "precision": 0.961111111111111,
                "recall": 0.9094973789700894,
                "f1-score": 0.9330885352917176,
                "support": 328.0
            },
            "weighted avg": {
                "precision": 0.9691056910569106,
                "recall": 0.9695121951219512,
                "f1-score": 0.968609129175747,
                "support": 328.0
            },
            "cross-entropy": 0.13144614667253732,
            "roc-auc": 0.9729417206290473,
            "f1-weighted": 0.968609129175747,
            "f1-macro": 0.9330885352917176,
            "f1-micro": 0.9695121951219512,
            "score": 0.9695121951219512
        }
    }
}
