seed = 0
batch_size = 256
patience = 16
n_epochs = inf
context_size = 96

[data]
seed = 0
cache = true
num_policy = "quantile"
cat_policy = "__null__"
path = ":data/TabZilla-OpenML-pc3-tid=3903-fold=0"
y_policy = "__null__"

[optimizer]
type = "AdamW"
lr = 1.889582693802601e-05
weight_decay = 4.3851702560851303e-05

[model]
num_embeddings = "__null__"
d_main = 124
context_dropout = 0.5027669444992823
d_multiplier = 2.0
encoder_n_blocks = 0
predictor_n_blocks = 1
mixer_normalization = "auto"
dropout0 = 0.05765904473637784
dropout1 = 0.0
normalization = "LayerNorm"
activation = "ReLU"
