{
    "function": "bin.ensemble.main",
    "config": {
        "seeds": [
            0
        ]
    },
    "single_model_function": "bin.tabr.main",
    "data": ":data/TabZilla-OpenML-Internet-Advertisements-tid=167125-fold=0",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.948509485094851,
                "recall": 0.9536784741144414,
                "f1-score": 0.9510869565217391,
                "support": 367.0
            },
            "1": {
                "precision": 0.9924578527062999,
                "recall": 0.9915780141843972,
                "f1-score": 0.9920177383592018,
                "support": 2256.0
            },
            "accuracy": 0.9862752573389248,
            "macro avg": {
                "precision": 0.9704836689005755,
                "recall": 0.9726282441494193,
                "f1-score": 0.9715523474404705,
                "support": 2623.0
            },
            "weighted avg": {
                "precision": 0.9863087673409162,
                "recall": 0.9862752573389248,
                "f1-score": 0.9862908619069147,
                "support": 2623.0
            },
            "cross-entropy": 0.04783381117648425,
            "roc-auc": 0.9961942238197383,
            "f1-weighted": 0.9862908619069147,
            "f1-macro": 0.9715523474404705,
            "f1-micro": 0.9862752573389248,
            "score": 0.9862752573389248
        },
        "val": {
            "0": {
                "precision": 1.0,
                "recall": 0.9347826086956522,
                "f1-score": 0.9662921348314607,
                "support": 46.0
            },
            "1": {
                "precision": 0.9894736842105263,
                "recall": 1.0,
                "f1-score": 0.9947089947089947,
                "support": 282.0
            },
            "accuracy": 0.9908536585365854,
            "macro avg": {
                "precision": 0.9947368421052631,
                "recall": 0.9673913043478262,
                "f1-score": 0.9805005647702276,
                "support": 328.0
            },
            "weighted avg": {
                "precision": 0.9909499358151476,
                "recall": 0.9908536585365854,
                "f1-score": 0.9907237033847063,
                "support": 328.0
            },
            "cross-entropy": 0.05779199103460335,
            "roc-auc": 0.9893617021276595,
            "f1-weighted": 0.9907237033847063,
            "f1-macro": 0.9805005647702276,
            "f1-micro": 0.9908536585365854,
            "score": 0.9908536585365854
        },
        "test": {
            "0": {
                "precision": 0.9487179487179487,
                "recall": 0.8043478260869565,
                "f1-score": 0.8705882352941177,
                "support": 46.0
            },
            "1": {
                "precision": 0.9688581314878892,
                "recall": 0.9929078014184397,
                "f1-score": 0.9807355516637478,
                "support": 282.0
            },
            "accuracy": 0.9664634146341463,
            "macro avg": {
                "precision": 0.958788040102919,
                "recall": 0.8986278137526982,
                "f1-score": 0.9256618934789327,
                "support": 328.0
            },
            "weighted avg": {
                "precision": 0.9660335936603975,
                "recall": 0.9664634146341463,
                "f1-score": 0.965288062172885,
                "support": 328.0
            },
            "cross-entropy": 0.12905575982949313,
            "roc-auc": 0.971477027443725,
            "f1-weighted": 0.965288062172885,
            "f1-macro": 0.9256618934789327,
            "f1-micro": 0.9664634146341463,
            "score": 0.9664634146341463
        }
    }
}
